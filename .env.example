# Environment Configuration Example
# Copy this file to .env and update the values as needed for your environment

# ===========================================
# GENERAL CONFIGURATION
# ===========================================
# Environment type (testing, development, production)
ENVIRONMENT=development

# API prefix for routes
# Testing: /test_api
# Development: /dev_api
# Production: /api
API_PREFIX=/api

# Debug mode
# Testing: True
# Development: True
# Production: False
DEBUG=True

# Logging level
# Testing: DEBUG
# Development: DEBUG
# Production: INFO
LOG_LEVEL=DEBUG

# ===========================================
# DATABASE CONFIGURATION
# ===========================================
# PostgreSQL Configuration (Production)
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=mydatabase
POSTGRES_HOST=db
POSTGRES_PORT=5432

# Database URL (automatically constructed from above in production)
# Testing: sqlite:///./test.db
# Development: sqlite:///./dev.db
# Production: postgresql://user:password@db:5432/mydatabase
DATABASE_URL=sqlite:///./dev.db

# ===========================================
# VECTOR DATABASE (QDRANT)
# ===========================================
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_API_KEY=your_qdrant_api_key

# ===========================================
# LLM PROVIDERS
# ===========================================
# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434

# Groq Configuration
GROQ_API_KEY=your_groq_api_key

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL_NAME=gpt-4o

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key
ANTHROPIC_MODEL_NAME=claude-3-opus-20240229

# Default Provider Configuration
# See llm providers E.g ollama, openai, groq, huggingface
PROVIDER=groq

# ===========================================
# MODEL PARAMETERS
# ===========================================
# Model name varies by environment
# Testing: test-model
# Development: llama3.2:1b
# Production: production-model
# E.g llama3.2:3b, openai/gpt-oss-120b
MODEL_NAME=openai/gpt-oss-120b

# Maximum tokens varies by environment
# Testing: 100
# Development: 500
# Production: 2000
MAX_TOKENS=500

# Temperature (0.0-1.0)
# Testing: 0.5
# Development: 0.6
# Production: 0.7
TEMPERATURE=0.6

# Top P (0.0-1.0)
# Testing: 0.9
# Development: 0.9
# Production: 0.95
TOP_P=0.9

# Frequency Penalty
# Testing: 0.0
# Development: 0.05
# Production: 0.1
FREQUENCY_PENALTY=0.05

# Presence Penalty
# Testing: 0.0
# Development: 0.05
# Production: 0.1
PRESENCE_PENALTY=0.05

# ===========================================
# CORS CONFIGURATION
# ===========================================
# CORS Origins (comma-separated)
# Development: http://localhost:3000,http://localhost:3001
# Production: https://your-production-domain.com,https://another-production-domain.com
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# CORS Methods (comma-separated)
CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS

# CORS Headers (comma-separated)
CORS_HEADERS=Content-Type,Authorization

# ===========================================
# RATE LIMITING
# ===========================================
# Rate limit per minute
# Testing: 50
# Development: 200
# Production: 500
RATE_LIMIT_PER_MINUTE=200

# Concurrent requests
# Testing: 10
# Development: 50
# Production: 100
CONCURRENT_REQUESTS=50